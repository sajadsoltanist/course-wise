"""
LLM integration service for CourseWise.

This module provides the LLMService class for OpenAI integration,
specifically for grade text parsing and course recommendation functionality.
"""

import json
import re
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from openai import AsyncOpenAI
from loguru import logger

from app.config import settings


@dataclass
class ParsedGrade:
    """Represents a parsed grade from user input."""
    course_code: str
    course_name: Optional[str]
    grade: Optional[float]
    status: str  # 'passed', 'failed', 'withdrawn'
    semester_taken: Optional[int] = None
    confidence: float = 1.0


@dataclass
class GradeParseResult:
    """Result of grade text parsing operation."""
    success: bool
    parsed_grades: List[ParsedGrade]
    warnings: List[str]
    confidence: float
    raw_text: str
    error_message: Optional[str] = None


class LLMService:
    """
    Service for LLM operations using OpenAI API.
    
    Handles grade text parsing, course validation, and provides
    structured responses for bot interaction.
    """
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4o"):
        """
        Initialize LLM service.
        
        Args:
            api_key: OpenAI API key (uses settings if None)
            model: OpenAI model to use for operations
        """
        self.api_key = api_key or settings.openai_api_key
        self.model = model
        self.client = AsyncOpenAI(api_key=self.api_key)
        
        logger.info(f"Initialized LLM service with model: {model}")
    
    async def parse_grades_text(self, text: str, valid_courses: Optional[List[dict]] = None) -> GradeParseResult:
        """
        Parse grade text input into structured format.
        
        Args:
            text: Raw grade text from user
            valid_courses: List of valid course codes for validation
            
        Returns:
            GradeParseResult with parsed grades and metadata
        """
        try:
            logger.info(f"Parsing grade text: {text[:100]}...")
            
            # Prepare the prompt for grade parsing
            prompt = self._prepare_grade_parsing_prompt(text, valid_courses or [])
            
            # Call OpenAI API
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert at parsing Iranian university grade information. Parse the user's grade text into structured JSON format."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.1,  # Low temperature for consistent parsing
                max_tokens=1500
            )
            
            # Parse the LLM response
            result = self._parse_llm_response(response.choices[0].message.content, text)
            
            logger.info(f"Successfully parsed {len(result.parsed_grades)} grades with confidence {result.confidence}")
            return result
            
        except Exception as e:
            logger.error(f"Error parsing grades: {e}")
            return GradeParseResult(
                success=False,
                parsed_grades=[],
                warnings=[],
                confidence=0.0,
                raw_text=text,
                error_message=f"Failed to parse grades: {str(e)}"
            )
    
    def _prepare_grade_parsing_prompt(self, text: str, valid_courses: List[str]) -> str:
        """
        Prepare the prompt for grade parsing.
        
        Args:
            text: User's grade text
            valid_courses: List of valid course codes
            
        Returns:
            Formatted prompt for LLM
        """
        prompt = f"""
Parse the following grade text from an Iranian university student. Extract course codes, names, grades, and status.

**Input Text:** "{text}"

**Valid Courses (Code â†’ Name):**
{self._format_course_list(valid_courses) if valid_courses else 'No course list provided - infer from text'}

**Instructions:**
1. Extract each course mentioned in the text
2. Match Persian course names to course codes using the Valid Courses list above
3. If exact match not found, find the closest match or leave course_code as null
4. Extract numerical grades (0-20 scale) or status (passed/failed)
5. Extract semester when course was taken (if mentioned)
6. Determine status: "passed" (grade â‰¥ 10), "failed" (grade < 10 or explicitly failed), "withdrawn"
7. Provide confidence score (0-1) for each parsing

**Matching Examples:**
- "Ø±ÛŒØ§Ø¶ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ 1" â†’ MATH101
- "Ø²Ø¨Ø§Ù† Ø¹Ù…ÙˆÙ…ÛŒ" â†’ ENG101
- "ØªØ±Ø¨ÛŒØª Ø¨Ø¯Ù†ÛŒ" â†’ PE101

**Output Format (JSON):**
```json
{{
    "success": true,
    "parsed_grades": [
        {{
            "course_code": "CS101",
            "course_name": "Programming Fundamentals",
            "grade": 18.5,
            "status": "passed",
            "semester_taken": 1,
            "confidence": 0.95
        }},
        {{
            "course_code": "MATH201", 
            "course_name": "Calculus",
            "grade": null,
            "status": "failed",
            "semester_taken": 2,
            "confidence": 0.90
        }}
    ],
    "warnings": ["Unknown course code: PHYS101"],
    "confidence": 0.92
}}
```

**Notes:**
- Iranian grading scale: 0-20 (passing grade â‰¥ 10)
- Common formats: "Math1: 17", "CS101: 18", "Physics: failed", "Data Structure = 19.5"
- Handle Persian/Farsi course names if present
- Extract semester info if mentioned: "ØªØ±Ù… 1", "ØªØ±Ù… Ø§ÙˆÙ„", "semester 2", etc.
- If semester not mentioned, leave semester_taken as null
- Flag unknown course codes as warnings
"""
        return prompt
    
    def _format_course_list(self, course_list: List[dict]) -> str:
        """Format course list for LLM prompt."""
        if not course_list:
            return "No courses available"
            
        formatted = []
        for course in course_list[:30]:  # Limit to avoid token overflow
            code = course.get("code", "")
            name = course.get("name", "")
            if code and name:
                formatted.append(f"- {code}: {name}")
        
        return "\n".join(formatted) if formatted else "No valid courses found"
    
    def _parse_llm_response(self, response_text: str, original_text: str) -> GradeParseResult:
        """
        Parse LLM response into GradeParseResult.
        
        Args:
            response_text: Raw response from LLM
            original_text: Original user input
            
        Returns:
            Parsed GradeParseResult
        """
        try:
            # Extract JSON from response (handle code blocks)
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                json_text = json_match.group(1)
            else:
                # Try to find JSON in the response
                json_text = response_text
            
            # Parse JSON
            data = json.loads(json_text)
            
            # Convert to ParsedGrade objects
            parsed_grades = []
            for grade_data in data.get('parsed_grades', []):
                parsed_grade = ParsedGrade(
                    course_code=grade_data.get('course_code', ''),
                    course_name=grade_data.get('course_name'),
                    grade=grade_data.get('grade'),
                    status=grade_data.get('status', 'unknown'),
                    semester_taken=grade_data.get('semester_taken'),
                    confidence=grade_data.get('confidence', 0.5)
                )
                parsed_grades.append(parsed_grade)
            
            return GradeParseResult(
                success=data.get('success', False),
                parsed_grades=parsed_grades,
                warnings=data.get('warnings', []),
                confidence=data.get('confidence', 0.5),
                raw_text=original_text
            )
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM JSON response: {e}")
            logger.debug(f"LLM response was: {response_text}")
            
            # Fallback: try simple regex parsing
            return self._fallback_grade_parsing(original_text)
            
        except Exception as e:
            logger.error(f"Error processing LLM response: {e}")
            return GradeParseResult(
                success=False,
                parsed_grades=[],
                warnings=[f"Failed to process LLM response: {str(e)}"],
                confidence=0.0,
                raw_text=original_text,
                error_message=str(e)
            )
    
    def _fallback_grade_parsing(self, text: str) -> GradeParseResult:
        """
        Fallback parsing using regex when LLM parsing fails.
        
        Args:
            text: Original user text
            
        Returns:
            GradeParseResult with basic parsing
        """
        logger.warning("Using fallback regex parsing for grades")
        
        parsed_grades = []
        warnings = ["Using basic parsing - LLM parsing failed"]
        
        # Common patterns for grade text
        patterns = [
            r'([A-Z]+\d+)[:=]\s*(\d+(?:\.\d+)?)',  # CS101: 18
            r'([A-Z]+\d+)[:=]\s*(failed?|pass)',    # CS101: failed
            r'(\w+)[:=]\s*(\d+(?:\.\d+)?)',         # Math: 17
            r'(\w+)[:=]\s*(failed?|pass)',          # Math: failed
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                course_code = match.group(1).upper()
                grade_str = match.group(2).lower()
                
                if grade_str in ['failed', 'fail']:
                    grade = None
                    status = 'failed'
                elif grade_str in ['passed', 'pass']:
                    grade = None
                    status = 'passed'
                else:
                    try:
                        grade = float(grade_str)
                        status = 'passed' if grade >= 10 else 'failed'
                    except ValueError:
                        continue
                
                parsed_grade = ParsedGrade(
                    course_code=course_code,
                    course_name=None,
                    grade=grade,
                    status=status,
                    confidence=0.7  # Lower confidence for regex parsing
                )
                parsed_grades.append(parsed_grade)
        
        return GradeParseResult(
            success=len(parsed_grades) > 0,
            parsed_grades=parsed_grades,
            warnings=warnings,
            confidence=0.7,
            raw_text=text
        )
    
    async def validate_course_codes(self, course_codes: List[str], 
                                   known_courses: List[str]) -> Tuple[List[str], List[str]]:
        """
        Validate course codes against known course list.
        
        Args:
            course_codes: List of course codes to validate
            known_courses: List of known/valid course codes
            
        Returns:
            Tuple of (valid_codes, invalid_codes)
        """
        valid_codes = []
        invalid_codes = []
        
        for code in course_codes:
            code_upper = code.upper()
            if code_upper in [c.upper() for c in known_courses]:
                valid_codes.append(code_upper)
            else:
                invalid_codes.append(code)
        
        if invalid_codes:
            logger.warning(f"Invalid course codes detected: {invalid_codes}")
        
        return valid_codes, invalid_codes
    
    def format_grades_for_confirmation(self, parse_result: GradeParseResult) -> str:
        """
        Format parsed grades for user confirmation.
        
        Args:
            parse_result: Result from grade parsing
            
        Returns:
            Formatted string for user display
        """
        if not parse_result.success or not parse_result.parsed_grades:
            return "L Could not parse any grades from your input."
        
        lines = ["=ï¿½ **Detected Grades:**\n"]
        
        for i, grade in enumerate(parse_result.parsed_grades, 1):
            status_emoji = "" if grade.status == "passed" else "L" if grade.status == "failed" else "ï¿½"
            grade_text = f"{grade.grade:.1f}" if grade.grade is not None else grade.status
            
            line = f"{i}. {status_emoji} **{grade.course_code}**"
            if grade.course_name:
                line += f" ({grade.course_name})"
            line += f": {grade_text}"
            if grade.semester_taken:
                line += f" - ØªØ±Ù… {grade.semester_taken}"
            
            lines.append(line)
        
        if parse_result.warnings:
            lines.append(f"\nï¿½ **Warnings:**")
            for warning in parse_result.warnings:
                lines.append(f"âš ï¸ {warning}")
        
        lines.append(f"\nðŸ“Š **Confidence:** {parse_result.confidence:.0%}")
        lines.append(f"\nðŸ“ **Original text:** {parse_result.raw_text}")
        
        return "\n".join(lines)
    
    async def generate_course_recommendations(
        self,
        context: str,
        student_preferences: Optional[Dict[str, Any]] = None,
        available_courses: Optional[List[Dict[str, Any]]] = None
    ) -> Dict[str, Any]:
        """
        Generate course recommendations using LLM.
        
        Args:
            context: Formatted context about student and academic rules
            student_preferences: User preferences for course selection
            available_courses: List of available courses for the semester
            
        Returns:
            Dict with LLM recommendations and analysis
        """
        try:
            logger.info("Generating course recommendations using LLM")
            
            # Prepare the recommendation prompt
            prompt = self._prepare_recommendation_prompt(context, student_preferences, available_courses)
            
            # Log prompt in debug mode only
            logger.debug(f"Sending prompt to LLM (length: {len(prompt)} chars)")
            
            # Call OpenAI API
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """Ø´Ù…Ø§ ÛŒÚ© Ù…Ø´Ø§ÙˆØ± ØªØ­ØµÛŒÙ„ÛŒ Ø®Ø¨Ø±Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒØ§Ù† Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ± Ø§ÛŒØ±Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. 
                        ÙˆØ¸ÛŒÙÙ‡ Ø´Ù…Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯Ø§Ù†Ù‡ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ ÙˆØ§Ø­Ø¯ Ø§Ø³Øª.
                        
                        Ø¯Ø± Ù¾Ø§Ø³Ø® Ø®ÙˆØ¯:
                        1. Ù‚ÙˆØ§Ù†ÛŒÙ† ØªØ­ØµÛŒÙ„ÛŒ Ø±Ø§ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø±Ø¹Ø§ÛŒØª Ú©Ù†ÛŒØ¯
                        2. Ø§ÙˆÙ„ÙˆÛŒØª Ø±Ø§ Ø¨Ù‡ Ø¯Ø±ÙˆØ³ Ù…Ø±Ø¯ÙˆØ¯ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§ Ø¯Ù‡ÛŒØ¯  
                        3. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù…ØªØ¹Ø§Ø¯Ù„ Ùˆ Ø¨Ø¯ÙˆÙ† ØªØ¯Ø§Ø®Ù„ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯
                        4. ØªÙˆØ¶ÛŒØ­ Ø±ÙˆØ´Ù† Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø¯Ù‡ÛŒØ¯
                        5. Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ùˆ Ø¯Ø± ÙØ±Ù…Øª Ø®ÙˆØ§Ø³ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯"""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,  # Moderate creativity for recommendations
                max_tokens=2000
            )
            
            # Parse the LLM response
            llm_response = response.choices[0].message.content
            
            # Log response in debug mode only
            logger.debug(f"Received LLM response (length: {len(llm_response)} chars)")
            
            # Extract structured information from response
            recommendations = self._parse_recommendation_response(llm_response)
            
            logger.info(f"Generated {len(recommendations.get('courses', []))} course recommendations")
            
            return {
                "success": True,
                "recommendations": recommendations,
                "raw_response": llm_response,
                "analysis": self._analyze_llm_recommendations(recommendations, available_courses or [])
            }
            
        except Exception as e:
            logger.error(f"Error generating LLM recommendations: {e}")
            return {
                "success": False,
                "error": str(e),
                "recommendations": {},
                "raw_response": "",
                "analysis": {}
            }
    
    def _prepare_recommendation_prompt(
        self,
        context: str, 
        preferences: Optional[Dict[str, Any]] = None,
        available_courses: Optional[List[Dict[str, Any]]] = None
    ) -> str:
        """
        Prepare prompt for course recommendation.
        
        Args:
            context: Student and academic context
            preferences: User preferences
            available_courses: Available courses list
            
        Returns:
            Formatted prompt for LLM
        """
        prompt_sections = [context]
        
        # Add user preferences if provided
        if preferences:
            prompt_sections.append(f"""
# ØªØ±Ø¬ÛŒØ­Ø§Øª Ø¯Ø§Ù†Ø´Ø¬Ùˆ

**ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯ Ù…Ø·Ù„ÙˆØ¨:** {preferences.get('desired_credits', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
**Ø¹Ù„Ø§Ù‚Ù‡â€ŒÙ…Ù†Ø¯ÛŒâ€ŒÙ‡Ø§:** {preferences.get('interests', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
**Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ ØªØ±Ø¬ÛŒØ­ÛŒ:** {preferences.get('preferred_schedule', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
**Ø³Ø§ÛŒØ± Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§:** {preferences.get('additional_notes', 'Ù†Ø¯Ø§Ø±Ø¯')}
            """)
        
        # Add detailed course list if available
        if available_courses:
            valid_courses = [c for c in available_courses if c.get("validation", {}).get("is_valid")]
            if valid_courses:
                course_details = []
                for course in valid_courses[:20]:  # Limit to avoid token overflow
                    credits = course.get("credits", {})
                    if isinstance(credits, dict):
                        total_credits = credits.get("theoretical", 0) + credits.get("practical", 0)
                    else:
                        total_credits = credits
                    
                    time_info = ", ".join(course.get("time_slots", ["Ù†Ø§Ù…Ø´Ø®Øµ"]))
                    priority = course.get("validation", {}).get("priority_score", 0)
                    
                    course_details.append(
                        f"- **{course['course_name']}** ({course['course_code']}): "
                        f"{total_credits} ÙˆØ§Ø­Ø¯ØŒ Ø§ÙˆÙ„ÙˆÛŒØª: {priority}, Ø²Ù…Ø§Ù†: {time_info}"
                    )
                
                prompt_sections.append(f"""
# Ø¬Ø²Ø¦ÛŒØ§Øª Ø¯Ø±ÙˆØ³ Ù…ÙˆØ¬ÙˆØ¯ (Û²Û° Ø¯Ø±Ø³ Ø§ÙˆÙ„)

{chr(10).join(course_details)}
                """)
        
        # Add final instructions
        prompt_sections.append("""
# Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³Ø§Ø³ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ ÙˆØ§Ø­Ø¯

## Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¹Ø¯Ù„):
- **Ù…Ø¹Ø¯Ù„ â‰¥ 17.0:** Ø­Ø¯Ø§Ú©Ø«Ø± 24 ÙˆØ§Ø­Ø¯
- **14.0 â‰¤ Ù…Ø¹Ø¯Ù„ < 17.0:** Ø­Ø¯Ø§Ú©Ø«Ø± 20 ÙˆØ§Ø­Ø¯  
- **12.0 â‰¤ Ù…Ø¹Ø¯Ù„ < 14.0:** Ø­Ø¯Ø§Ú©Ø«Ø± 16 ÙˆØ§Ø­Ø¯ (Ù…Ø´Ø±ÙˆØ·)
- **Ù…Ø¹Ø¯Ù„ < 12.0:** Ø­Ø¯Ø§Ú©Ø«Ø± 12 ÙˆØ§Ø­Ø¯ (Ø¯Ø± Ø®Ø·Ø± Ø§Ø®Ø±Ø§Ø¬)
- **ØªØ±Ù… Ù‚Ø¨Ù„ Ù…Ø´Ø±ÙˆØ·:** Ø­Ø¯Ø§Ú©Ø«Ø± 14 ÙˆØ§Ø­Ø¯ (ØµØ±Ù Ù†Ø¸Ø± Ø§Ø² Ù…Ø¹Ø¯Ù„ Ú©Ù„)
- **ØªØ±Ù… Ø§ÙˆÙ„:** Ø­Ø¯Ø§Ú©Ø«Ø± 18 ÙˆØ§Ø­Ø¯ (Ø¨Ø¯ÙˆÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù…Ø¹Ø¯Ù„)

## Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¯Ø±ÙˆØ³ Ø¹Ù…ÙˆÙ…ÛŒ:
- **Ø¯Ø±ÙˆØ³ Ù…Ø¹Ø§Ø±Ù Ø§Ø³Ù„Ø§Ù…ÛŒ:** Ø¯Ø± Ù‡Ø± ØªØ±Ù… ÙÙ‚Ø· ÛŒÚ© Ø¯Ø±Ø³ Ù…Ø¹Ø§Ø±Ù Ù‚Ø§Ø¨Ù„ Ø§Ù†ØªØ®Ø§Ø¨
- **Ø¯Ø±ÙˆØ³ Ø²Ø¨Ø§Ù†:** Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ØªØ±ØªÛŒØ¨ Ú¯Ø°Ø±Ø§Ù†Ø¯Ù‡ Ø´ÙˆÙ†Ø¯ (Ø²Ø¨Ø§Ù† Ù¾ÛŒØ´ â†’ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Û± â†’ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Û² â†’ Ø²Ø¨Ø§Ù† ØªØ®ØµØµÛŒ)
- **ØªØ±Ø¨ÛŒØª Ø¨Ø¯Ù†ÛŒ:** Ø­Ø¯Ø§Ú©Ø«Ø± 2 ÙˆØ§Ø­Ø¯ Ø¯Ø± Ú©Ù„ Ø¯ÙˆØ±Ù‡ (ØªØ±Ø¨ÛŒØª Ø¨Ø¯Ù†ÛŒ â†’ ÙˆØ±Ø²Ø´ Û±)
- **Ú©Ø§Ø±Ú¯Ø§Ù‡ Ø¹Ù…ÙˆÙ…ÛŒ:** Ø¢Ø´Ù†Ø§ÛŒÛŒ Ø¨Ø§ ØµÙ†Ø¹Øª â†’ Ú©Ø§Ø±Ø¢ÙØ±ÛŒÙ†ÛŒ

## Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø±ÙˆØ³:
1. **Ø¯Ø±ÙˆØ³ Ù…Ø±Ø¯ÙˆØ¯ÛŒ** (Ø§ÙˆÙ„ÙˆÛŒØª 100) - Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø§ÙˆÙ„ÙˆÛŒØª
2. **Ø¯Ø±ÙˆØ³ Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²** (Ø§ÙˆÙ„ÙˆÛŒØª 90) - Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Ø¯Ø±ÙˆØ³ Ø¢ÛŒÙ†Ø¯Ù‡
3. **Ø¯Ø±ÙˆØ³ ØªØ±Ù… Ø¬Ø§Ø±ÛŒ** (Ø§ÙˆÙ„ÙˆÛŒØª 80) - Ù…Ø·Ø§Ø¨Ù‚ Ú†Ø§Ø±Øª Ø¯Ø±Ø³ÛŒ
4. **Ø¯Ø±ÙˆØ³ Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡** (Ø§ÙˆÙ„ÙˆÛŒØª 70) - ØªÚ©Ù…ÛŒÙ„ Ø¯Ø±ÙˆØ³ Ø¹Ù…ÙˆÙ…ÛŒ

## Ù‚ÙˆØ§Ù†ÛŒÙ† Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø² Ùˆ Ù‡Ù…â€ŒÙ†ÛŒØ§Ø²:
- Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ù†Ù…Ø±Ù‡ â‰¥ 10 Ú¯Ø°Ø±Ø§Ù†Ø¯Ù‡ Ø´ÙˆÙ†Ø¯
- **Ø¯Ø±ÙˆØ³ Ù‡Ù…â€ŒÙ†ÛŒØ§Ø² Ø§Ø¬Ø¨Ø§Ø±ÛŒ:**
  - Ø±ÛŒØ§Ø¶ÛŒ Û± + Ø­Ù„ ØªÙ…Ø±ÛŒÙ† Ø±ÛŒØ§Ø¶ÛŒ Û±
  - ÙÛŒØ²ÛŒÚ© Û± + Ø­Ù„ ØªÙ…Ø±ÛŒÙ† ÙÛŒØ²ÛŒÚ© Û±  
  - Ø±ÛŒØ§Ø¶ÛŒ Û² + Ø­Ù„ ØªÙ…Ø±ÛŒÙ† Ø±ÛŒØ§Ø¶ÛŒ Û²
  - ÙÛŒØ²ÛŒÚ© Û² + Ø­Ù„ ØªÙ…Ø±ÛŒÙ† ÙÛŒØ²ÛŒÚ© Û²

## Ú†Ø§Ø±Øª Ø¯Ø±Ø³ÛŒ (ÙˆØ±ÙˆØ¯ÛŒ 1403 Ø¨Ù‡ Ø¨Ø¹Ø¯):
- **ØªØ±Ù… 1:** Ø±ÛŒØ§Ø¶ÛŒÛ±ØŒ ÙÛŒØ²ÛŒÚ©Û±ØŒ Ù…Ø¨Ø§Ù†ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±ØŒ Ø§Ù†Ø¯ÛŒØ´Ù‡ Ø§Ø³Ù„Ø§Ù…ÛŒÛ±ØŒ Ø¢ÛŒÛŒÙ† Ø²Ù†Ø¯Ú¯ÛŒ
- **ØªØ±Ù… 2:** Ø±ÛŒØ§Ø¶ÛŒÛ²ØŒ ÙÛŒØ²ÛŒÚ©Û²ØŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ØŒ Ø±ÛŒØ§Ø¶ÛŒØ§Øª Ú¯Ø³Ø³ØªÙ‡ØŒ Ù…Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù…Ù†Ø·Ù‚ÛŒØŒ Ú©Ø§Ø±Ú¯Ø§Ù‡ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±ØŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒÛ±ØŒ ØªØ§Ø±ÛŒØ® ØµØ¯Ø± Ø§Ø³Ù„Ø§Ù…ØŒ Ø¢Ø´Ù†Ø§ÛŒÛŒ Ø¨Ø§ ØµÙ†Ø¹Øª
- **ØªØ±Ù… 3:** Ø³Ø§Ø®ØªÙ…Ø§Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ØŒ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±ØŒ Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø¯ÛŒÙØ±Ø§Ù†Ø³ÛŒÙ„ØŒ Ø¢Ø²Ù…Ø§ÛŒØ´Ú¯Ø§Ù‡ Ù…Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù…Ù†Ø·Ù‚ÛŒØŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒÛ²ØŒ ÙØ§Ø±Ø³ÛŒØŒ Ú©Ø§Ø±Ø¢ÙØ±ÛŒÙ†ÛŒ
- **ØªØ±Ù… 4:** Ø·Ø±Ø§Ø­ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ØŒ Ù†Ø¸Ø±ÛŒÙ‡ Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ØŒ Ø¢Ø²Ù…Ø§ÛŒØ´Ú¯Ø§Ù‡ Ù…Ø¹Ù…Ø§Ø±ÛŒØŒ Ù…Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø§Ù„Ú©ØªØ±ÛŒÚ©ÛŒØŒ Ø¬Ø¨Ø± Ø®Ø·ÛŒØŒ Ø¢Ù…Ø§Ø± Ùˆ Ø§Ø­ØªÙ…Ø§Ù„ØŒ Ø²Ø¨Ø§Ù† ØªØ®ØµØµÛŒØŒ ØªØ§Ø±ÛŒØ® ÙØ±Ù‡Ù†Ú¯ Ø§Ø³Ù„Ø§Ù…

# Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù†Ù‡Ø§ÛŒÛŒ

Ù„Ø·ÙØ§Ù‹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙÙˆÙ‚ Ùˆ Ù‚ÙˆØ§Ù†ÛŒÙ† ØªØ­ØµÛŒÙ„ÛŒØŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¯Ø±ÙˆØ³ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† ØªØ±Ù… Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.

**ÙØ±Ù…Øª Ø®Ø±ÙˆØ¬ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±:**

ðŸ“š **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¯Ø±ÙˆØ³ Ø¨Ø±Ø§ÛŒ ØªØ±Ù…:**

ðŸ—“ï¸ **Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù‡ÙØªÚ¯ÛŒ:**

**Ø´Ù†Ø¨Ù‡:**
- [Ù†Ø§Ù… Ø¯Ø±Ø³] ([Ú©Ø¯ Ø¯Ø±Ø³]) - [Ø³Ø§Ø¹Øª Ú©Ù„Ø§Ø³] - [ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯] ÙˆØ§Ø­Ø¯ - Ø§Ø³ØªØ§Ø¯: [Ù†Ø§Ù… Ø§Ø³ØªØ§Ø¯]

**ÛŒÚ©Ø´Ù†Ø¨Ù‡:**
- [Ù†Ø§Ù… Ø¯Ø±Ø³] ([Ú©Ø¯ Ø¯Ø±Ø³]) - [Ø³Ø§Ø¹Øª Ú©Ù„Ø§Ø³] - [ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯] ÙˆØ§Ø­Ø¯ - Ø§Ø³ØªØ§Ø¯: [Ù†Ø§Ù… Ø§Ø³ØªØ§Ø¯]

**Ø¯ÙˆØ´Ù†Ø¨Ù‡:**
- [Ù†Ø§Ù… Ø¯Ø±Ø³] ([Ú©Ø¯ Ø¯Ø±Ø³]) - [Ø³Ø§Ø¹Øª Ú©Ù„Ø§Ø³] - [ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯] ÙˆØ§Ø­Ø¯ - Ø§Ø³ØªØ§Ø¯: [Ù†Ø§Ù… Ø§Ø³ØªØ§Ø¯]

**Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡:**
- [Ù†Ø§Ù… Ø¯Ø±Ø³] ([Ú©Ø¯ Ø¯Ø±Ø³]) - [Ø³Ø§Ø¹Øª Ú©Ù„Ø§Ø³] - [ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯] ÙˆØ§Ø­Ø¯ - Ø§Ø³ØªØ§Ø¯: [Ù†Ø§Ù… Ø§Ø³ØªØ§Ø¯]

**Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡:**
- [Ù†Ø§Ù… Ø¯Ø±Ø³] ([Ú©Ø¯ Ø¯Ø±Ø³]) - [Ø³Ø§Ø¹Øª Ú©Ù„Ø§Ø³] - [ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯] ÙˆØ§Ø­Ø¯ - Ø§Ø³ØªØ§Ø¯: [Ù†Ø§Ù… Ø§Ø³ØªØ§Ø¯]

**Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡:**
- [Ø¯Ø±ÙˆØ³ Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡ Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯]

**Ø¬Ù…Ø¹Ù‡:**
- [Ø¯Ø±ÙˆØ³ Ø¬Ù…Ø¹Ù‡ Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯]

ðŸ“Š **Ø®Ù„Ø§ØµÙ‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯:**
- **Ù…Ø¬Ù…ÙˆØ¹ ÙˆØ§Ø­Ø¯Ù‡Ø§:** [ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„] ÙˆØ§Ø­Ø¯
- **Ø¯Ø±ÙˆØ³ Ù…Ø±Ø¯ÙˆØ¯ÛŒ Ù¾ÙˆØ´Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡:** [ØªØ¹Ø¯Ø§Ø¯]
- **Ø¯Ø±ÙˆØ³ Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²:** [ØªØ¹Ø¯Ø§Ø¯]  
- **Ø¯Ø±ÙˆØ³ Ø¬Ø¯ÛŒØ¯:** [ØªØ¹Ø¯Ø§Ø¯]
- **Ø¯Ø±ÙˆØ³ Ø¹Ù…ÙˆÙ…ÛŒ:** [ØªØ¹Ø¯Ø§Ø¯]
- **Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ÙˆØ§Ø­Ø¯ Ø±Ø¹Ø§ÛŒØª Ø´Ø¯Ù‡:** [Ø¨Ù„Ù‡/Ø®ÛŒØ±]

ðŸ’¡ **ØªÙˆØ¬ÛŒÙ‡ Ø§Ù†ØªØ®Ø§Ø¨:**
[ØªÙˆØ¶ÛŒØ­ Ù…Ù†Ø·Ù‚ Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø±ÙˆØ³ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒÙ‡Ø§ØŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ Ùˆ Ú†Ø§Ø±Øª Ø¯Ø±Ø³ÛŒ]

âš ï¸ **Ù†Ú©Ø§Øª Ù…Ù‡Ù…:**
[Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ Ø¯Ø±Ø¨Ø§Ø±Ù‡ ØªØ¯Ø§Ø®Ù„ Ø²Ù…Ø§Ù†ÛŒØŒ Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§ØŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ]

**Ø§ØµÙˆÙ„ Ø±Ø¹Ø§ÛŒØª Ø´Ø¯Ù‡:** 
- Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ÙˆØ§Ø­Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¹Ø¯Ù„ Ùˆ ÙˆØ¶Ø¹ÛŒØª ØªØ­ØµÛŒÙ„ÛŒ
- Ø§ÙˆÙ„ÙˆÛŒØª Ø¯Ø±ÙˆØ³ Ù…Ø±Ø¯ÙˆØ¯ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²
- Ø±Ø¹Ø§ÛŒØª ØªØ±ØªÛŒØ¨ Ø¯Ø±ÙˆØ³ Ø¹Ù…ÙˆÙ…ÛŒ (Ø²Ø¨Ø§Ù†ØŒ Ù…Ø¹Ø§Ø±ÙØŒ Ú©Ø§Ø±Ú¯Ø§Ù‡)
- ØªØ¹Ø§Ø¯Ù„ Ø¨ÛŒÙ† Ø¯Ø±ÙˆØ³ Ø³Ø®Øª Ùˆ Ø¢Ø³Ø§Ù†
- Ø§Ø¬ØªÙ†Ø§Ø¨ Ø§Ø² ØªØ¯Ø§Ø®Ù„ Ø²Ù…Ø§Ù†ÛŒ
- **Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø­Ù„ ØªÙ…Ø±ÛŒÙ† Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ø¯Ø±Ø³ Ø§ØµÙ„ÛŒ** (Ø±ÛŒØ§Ø¶ÛŒØŒ ÙÛŒØ²ÛŒÚ©)
        """)
        
        return "\n".join(prompt_sections)
    
    def _parse_recommendation_response(self, response: str) -> Dict[str, Any]:
        """
        Parse LLM recommendation response into structured format.
        
        Args:
            response: Raw LLM response text
            
        Returns:
            Structured recommendation data
        """
        try:
            recommendations = {
                "weekly_schedule": {},
                "summary": {},
                "explanation": "",
                "warnings": [],
                "courses": []
            }
            
            # Try to parse as JSON first (LLM might return structured JSON)
            if response.strip().startswith('```json') and '```' in response:
                json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
                if json_match:
                    try:
                        import json
                        json_data = json.loads(json_match.group(1))
                        if "recommended_courses" in json_data:
                            for course in json_data["recommended_courses"]:
                                course_info = {
                                    'course_code': course.get('course_code', ''),
                                    'course_name': course.get('course_name', ''),
                                    'credits': course.get('credits', {}),
                                    'time_slots': ['Ù†Ø§Ù…Ø´Ø®Øµ'],
                                    'instructor': course.get('instructor', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
                                    'type': course.get('type', 'ØªØ®ØµØµÛŒ'),
                                    'priority': course.get('priority', 'Ù…ØªÙˆØ³Ø·'),
                                    'reason': course.get('reason', '')
                                }
                                recommendations["courses"].append(course_info)
                            
                            # Create simple weekly schedule from courses
                            weekdays = ["Ø´Ù†Ø¨Ù‡", "ÛŒÚ©Ø´Ù†Ø¨Ù‡", "Ø¯ÙˆØ´Ù†Ø¨Ù‡", "Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡", "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡", "Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡"]
                            for i, course in enumerate(recommendations["courses"]):
                                if i < len(weekdays):
                                    day = weekdays[i]
                                    recommendations["weekly_schedule"][day] = [course]
                            
                            # Extract analysis from JSON
                            recommendations["explanation"] = json_data.get("analysis", "")
                            recommendations["summary"] = {
                                "total_credits": json_data.get("total_credits", "Ù†Ø§Ù…Ø´Ø®Øµ"),
                                "course_count": len(recommendations["courses"]),
                                "passed_grades": len(json_data.get("mapped_grades", []))
                            }
                            
                            logger.debug(f"Parsed JSON response with {len(recommendations['courses'])} courses")
                            return recommendations
                    except json.JSONDecodeError as e:
                        logger.warning(f"Failed to parse JSON response: {e}, falling back to text parsing")
            
            # Fallback to original text parsing for weekly schedule format
            weekdays = ["Ø´Ù†Ø¨Ù‡", "ÛŒÚ©Ø´Ù†Ø¨Ù‡", "Ø¯ÙˆØ´Ù†Ø¨Ù‡", "Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡", "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡", "Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡", "Ø¬Ù…Ø¹Ù‡"]
            
            for day in weekdays:
                day_pattern = rf"\*\*{day}:\*\*(.*?)(?=\*\*(?:{'|'.join(weekdays)}|Ø®Ù„Ø§ØµÙ‡|ØªÙˆØ¬ÛŒÙ‡|Ù†Ú©Ø§Øª)|\Z)"
                day_match = re.search(day_pattern, response, re.DOTALL)
                
                if day_match:
                    day_content = day_match.group(1).strip()
                    courses_on_day = []
                    
                    # Extract courses for this day
                    course_lines = [line.strip() for line in day_content.split('\n') if line.strip() and line.strip().startswith('-')]
                    
                    for line in course_lines:
                        course_info = self._extract_course_from_line(line)
                        if course_info:
                            courses_on_day.append(course_info)
                            
                            # Add to global course list if not already there
                            if not any(c['course_code'] == course_info['course_code'] for c in recommendations["courses"]):
                                recommendations["courses"].append(course_info)
                    
                    recommendations["weekly_schedule"][day] = courses_on_day
            
            # Fallback: if no courses found, try to extract course codes directly
            if not recommendations["courses"]:
                logger.warning("No courses found in weekly schedule, trying fallback extraction")
                recommendations["courses"] = self._fallback_course_extraction(response)
            
            # Extract summary
            summary_pattern = r"\*\*Ø®Ù„Ø§ØµÙ‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯:\*\*(.*?)(?=ðŸ’¡|\*\*ØªÙˆØ¬ÛŒÙ‡|\Z)"
            summary_match = re.search(summary_pattern, response, re.DOTALL)
            if summary_match:
                summary_text = summary_match.group(1).strip()
                recommendations["summary"] = self._parse_summary_section(summary_text)
            
            # Extract explanation
            explanation_pattern = r"ðŸ’¡\s*\*\*ØªÙˆØ¬ÛŒÙ‡ Ø§Ù†ØªØ®Ø§Ø¨:\*\*(.*?)(?=âš ï¸|\*\*Ù†Ú©Ø§Øª|\Z)"
            explanation_match = re.search(explanation_pattern, response, re.DOTALL)
            if explanation_match:
                recommendations["explanation"] = explanation_match.group(1).strip()
            
            # Extract warnings/notes
            warnings_pattern = r"âš ï¸\s*\*\*Ù†Ú©Ø§Øª Ù…Ù‡Ù…:\*\*(.*?)(?=\*\*Ù…Ù‡Ù…|\Z)"
            warnings_match = re.search(warnings_pattern, response, re.DOTALL)
            if warnings_match:
                warnings_text = warnings_match.group(1).strip()
                recommendations["warnings"] = [line.strip() for line in warnings_text.split('\n') if line.strip()]
            
            return recommendations
            
        except Exception as e:
            logger.error(f"Error parsing LLM recommendation response: {e}")
            return {"error": str(e), "courses": [], "weekly_schedule": {}}
    
    def _extract_course_from_line(self, line: str) -> Optional[Dict[str, Any]]:
        """
        Extract course information from a single line.
        
        Args:
            line: Line containing course info
            
        Returns:
            Course information dict or None
        """
        try:
            # Pattern: - [Ù†Ø§Ù… Ø¯Ø±Ø³] ([Ú©Ø¯ Ø¯Ø±Ø³]) - [Ø³Ø§Ø¹Øª] - [ÙˆØ§Ø­Ø¯] ÙˆØ§Ø­Ø¯ - Ø§Ø³ØªØ§Ø¯: [Ù†Ø§Ù…]
            pattern = r'-\s*(.+?)\s*\(([A-Z0-9]+)\)\s*-\s*(.+?)\s*-\s*(\d+)\s*ÙˆØ§Ø­Ø¯(?:\s*-\s*Ø§Ø³ØªØ§Ø¯:\s*(.+?))?'
            
            match = re.search(pattern, line)
            if match:
                return {
                    "course_name": match.group(1).strip(),
                    "course_code": match.group(2).strip(),
                    "time_slot": match.group(3).strip(),
                    "credits": int(match.group(4)),
                    "instructor": match.group(5).strip() if match.group(5) else "Ù†Ø§Ù…Ø´Ø®Øµ"
                }
            
            # Simpler pattern if the above doesn't match
            simple_pattern = r'-\s*(.+?)\s*\(([A-Z0-9]+)\)'
            simple_match = re.search(simple_pattern, line)
            if simple_match:
                return {
                    "course_name": simple_match.group(1).strip(),
                    "course_code": simple_match.group(2).strip(),
                    "time_slot": "Ù†Ø§Ù…Ø´Ø®Øµ",
                    "credits": 0,
                    "instructor": "Ù†Ø§Ù…Ø´Ø®Øµ"
                }
            
            return None
            
        except Exception as e:
            logger.warning(f"Could not parse course line: {line} - {e}")
            return None
    
    def _parse_summary_section(self, summary_text: str) -> Dict[str, Any]:
        """
        Parse summary section from LLM response.
        
        Args:
            summary_text: Summary section text
            
        Returns:
            Parsed summary data
        """
        summary = {}
        
        # Extract total credits
        credits_match = re.search(r'Ù…Ø¬Ù…ÙˆØ¹ ÙˆØ§Ø­Ø¯Ù‡Ø§.*?(\d+)', summary_text)
        if credits_match:
            summary["total_credits"] = int(credits_match.group(1))
        
        # Extract failed courses count
        failed_match = re.search(r'Ø¯Ø±ÙˆØ³ Ù…Ø±Ø¯ÙˆØ¯ÛŒ.*?(\d+)', summary_text)
        if failed_match:
            summary["failed_courses_covered"] = int(failed_match.group(1))
        
        # Extract prerequisite courses count
        prereq_match = re.search(r'Ø¯Ø±ÙˆØ³ Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø².*?(\d+)', summary_text)
        if prereq_match:
            summary["prerequisite_courses"] = int(prereq_match.group(1))
        
        # Extract new courses count
        new_match = re.search(r'Ø¯Ø±ÙˆØ³ Ø¬Ø¯ÛŒØ¯.*?(\d+)', summary_text)
        if new_match:
            summary["new_courses"] = int(new_match.group(1))
        
        # Extract difficulty balance
        difficulty_match = re.search(r'ØªØ¹Ø§Ø¯Ù„ Ø³Ø®ØªÛŒ.*?(Ø¢Ø³Ø§Ù†|Ù…ØªÙˆØ³Ø·|Ø³Ø®Øª|Ù…ØªØ¹Ø§Ø¯Ù„)', summary_text)
        if difficulty_match:
            summary["difficulty_balance"] = difficulty_match.group(1)
        
        return summary
    
    def _analyze_llm_recommendations(self, recommendations: Dict[str, Any], available_courses: List[Dict]) -> Dict[str, Any]:
        """
        Analyze quality of LLM recommendations.
        
        Args:
            recommendations: Parsed LLM recommendations
            available_courses: List of available courses
            
        Returns:
            Analysis results
        """
        analysis = {
            "validity_score": 0,
            "coverage_score": 0,
            "balance_score": 0,
            "issues": [],
            "strengths": []
        }
        
        recommended_courses = recommendations.get("courses", [])
        
        if not recommended_courses:
            analysis["issues"].append("No courses recommended")
            return analysis
        
        # Check if recommended courses are actually available
        available_codes = {course["course_code"] for course in available_courses}
        recommended_codes = {course["course_code"] for course in recommended_courses}
        
        valid_recommendations = recommended_codes.intersection(available_codes)
        invalid_recommendations = recommended_codes - available_codes
        
        # Calculate validity score
        if recommended_codes:
            analysis["validity_score"] = len(valid_recommendations) / len(recommended_codes) * 100
        
        if invalid_recommendations:
            analysis["issues"].append(f"Invalid course codes: {', '.join(invalid_recommendations)}")
        else:
            analysis["strengths"].append("All recommended courses are available")
        
        # Check credit distribution
        total_credits_raw = recommendations.get("summary", {}).get("total_credits", 0)
        try:
            # Convert to int if it's a string
            if isinstance(total_credits_raw, str):
                total_credits = int(total_credits_raw.split()[0]) if total_credits_raw.split() else 0
            else:
                total_credits = int(total_credits_raw) if total_credits_raw else 0
            
            if 12 <= total_credits <= 24:
                analysis["strengths"].append(f"Appropriate credit count: {total_credits}")
            else:
                analysis["issues"].append(f"Credit count may be inappropriate: {total_credits}")
        except (ValueError, IndexError, TypeError):
            analysis["issues"].append("Could not determine credit count")
        
        # Check daily distribution
        weekly_schedule = recommendations.get("weekly_schedule", {})
        daily_counts = [len(courses) for courses in weekly_schedule.values()]
        
        if daily_counts and max(daily_counts) <= 3:
            analysis["strengths"].append("Good daily distribution")
            analysis["balance_score"] = 80
        else:
            analysis["issues"].append("Some days may be overloaded")
            analysis["balance_score"] = 50
        
        # Overall coverage score
        if len(valid_recommendations) >= 3:
            analysis["coverage_score"] = 80
            analysis["strengths"].append("Good course coverage")
        else:
            analysis["coverage_score"] = 40
            analysis["issues"].append("Limited course coverage")
        
        return analysis

    def _fallback_course_extraction(self, response: str) -> List[Dict[str, Any]]:
        """Fallback method to extract course codes from any format"""
        try:
            import re
            courses = []
            
            # Look for actual course codes from offerings first, then fallback to generic codes
            code_patterns = [
                r'([0-9]{10})',  # 10-digit codes like 7000031535, 4628164737
                r'\b([0-9]{7,12})\b',  # 7-12 digit codes from offerings  
                r'Ù…Ø¹Ø§Ø¯Ù„Ø§Øª_Ø¯ÛŒÙØ±Ø§Ù†Ø³ÛŒÙ„|Ø³Ø§Ø®ØªØ§Ø±_Ø¯Ø§Ø¯Ù‡|Ø¢Ù…Ø§Ø±_Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª|Ù…Ø¹Ù…Ø§Ø±ÛŒ_Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±|Ù…Ù‡Ø§Ø±ØªÙ‡Ø§ÛŒ_Ù†Ø±Ù…|Ú©Ø§Ø±Ø¢ÙØ±ÛŒÙ†ÛŒ',  # Course keys from offerings
                r'\(([A-Z0-9_]+)\)',  # (CS101) or (code in parentheses)
                r'([A-Z]+[0-9]+)',  # Generic codes like CS101 (lowest priority)
            ]
            
            for pattern in code_patterns:
                matches = re.findall(pattern, response)
                for match in matches:
                    # Skip very long numbers that aren't course codes
                    if len(match) > 15 or len(match) < 2:
                        continue
                    
                    # Add if not already in list
                    if not any(c.get('course_code') == match for c in courses):
                        # Try to find course info from offerings
                        course_info = self._find_course_in_offerings(match)
                        
                        courses.append({
                            'course_code': match,
                            'course_name': course_info.get('course_name', f'Ø¯Ø±Ø³ {match}'),
                            'credits': course_info.get('credits', {'theoretical': 3, 'practical': 0}),
                            'time_slots': course_info.get('time_slots', ['Ù†Ø§Ù…Ø´Ø®Øµ']),
                            'instructor': course_info.get('instructor', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
                            'exam_date': course_info.get('exam_date', '')
                        })
            
            logger.debug(f"Fallback extraction found {len(courses)} courses")
            return courses[:10]  # Limit to reasonable number
            
        except Exception as e:
            logger.error(f"Error in fallback course extraction: {e}")
            return []
    
    def _find_course_in_offerings(self, course_code: str) -> Dict[str, Any]:
        """Find course information from offerings data"""
        try:
            from pathlib import Path
            import json
            
            # Load offerings file
            offerings_path = Path("data/offerings/mehr_1404_new.json")
            
            if offerings_path.exists():
                with open(offerings_path, 'r', encoding='utf-8') as f:
                    offerings = json.load(f)
                
                # Search in all sections of offerings
                def search_in_courses(courses_list):
                    for course in courses_list:
                        if course.get('course_code') == course_code:
                            return course
                    return None
                
                # Search in entry year groups
                for entry_year, entry_data in offerings.get("entry_year_groups", {}).items():
                    for semester_num, semester_data in entry_data.get("semesters", {}).items():
                        found = search_in_courses(semester_data.get("courses", []))
                        if found:
                            return found
                
                # Search in open courses
                found = search_in_courses(offerings.get("open_courses", {}).get("courses", []))
                if found:
                    return found
                
                # Search in general courses
                found = search_in_courses(offerings.get("general_courses", {}).get("courses", []))
                if found:
                    return found
            
            return {}  # Not found
            
        except Exception as e:
            logger.error(f"Error searching course in offerings: {e}")
            return {}

    async def health_check(self) -> bool:
        """
        Check if LLM service is healthy and can connect to OpenAI.
        
        Returns:
            True if service is healthy, False otherwise
        """
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=5
            )
            return True
        except Exception as e:
            logger.error(f"LLM health check failed: {e}")
            return False